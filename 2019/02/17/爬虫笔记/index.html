<!DOCTYPE html>












  


<html class="theme-next pisces use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">


























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=6.7.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.7.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/qi.png?v=6.7.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/qi.png?v=6.7.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.7.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '6.7.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="安装scrapy框架 安装scrapy：pip install scrapy windows下，还需要安装pypiwin32，防止报错。pip install scrapy。报Visual C++ 14.0 is required错误的话，安装Visual C++ Build Tools，Visual C++ Build Tools 2015下载地址  创建项目和爬虫 创建项目：scapy sta">
<meta name="keywords" content="scrapy">
<meta property="og:type" content="article">
<meta property="og:title" content="爬虫笔记 - scrapy">
<meta property="og:url" content="http://wuliuqi.top/2019/02/17/爬虫笔记/index.html">
<meta property="og:site_name" content="阿珍爱上了阿强">
<meta property="og:description" content="安装scrapy框架 安装scrapy：pip install scrapy windows下，还需要安装pypiwin32，防止报错。pip install scrapy。报Visual C++ 14.0 is required错误的话，安装Visual C++ Build Tools，Visual C++ Build Tools 2015下载地址  创建项目和爬虫 创建项目：scapy sta">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2019-02-18T14:43:39.071Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="爬虫笔记 - scrapy">
<meta name="twitter:description" content="安装scrapy框架 安装scrapy：pip install scrapy windows下，还需要安装pypiwin32，防止报错。pip install scrapy。报Visual C++ 14.0 is required错误的话，安装Visual C++ Build Tools，Visual C++ Build Tools 2015下载地址  创建项目和爬虫 创建项目：scapy sta">






  <link rel="canonical" href="http://wuliuqi.top/2019/02/17/爬虫笔记/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>爬虫笔记 - scrapy | 阿珍爱上了阿强</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">阿珍爱上了阿强</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">在一个有星星的夜晚</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://wuliuqi.top/2019/02/17/爬虫笔记/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="WP">
      <meta itemprop="description" content="飞机从头顶飞过<br>流星也划破那夜空">
      <meta itemprop="image" content="/images/memory.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="阿珍爱上了阿强">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">爬虫笔记 - scrapy

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-02-17 15:25:48" itemprop="dateCreated datePublished" datetime="2019-02-17T15:25:48+08:00">2019-02-17</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-02-18 22:43:39" itemprop="dateModified" datetime="2019-02-18T22:43:39+08:00">2019-02-18</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/学习笔记/" itemprop="url" rel="index"><span itemprop="name">学习笔记</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/学习笔记/爬虫/" itemprop="url" rel="index"><span itemprop="name">爬虫</span></a></span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/02/17/爬虫笔记/#comments" itemprop="discussionUrl">
                  <span class="post-meta-item-text">评论数：</span> <span class="post-comments-count valine-comment-count" data-xid="/2019/02/17/爬虫笔记/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
            <span id="/2019/02/17/爬虫笔记/" class="leancloud_visitors" data-flag-title="爬虫笔记 - scrapy">
              <span class="post-meta-divider">|</span>
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              
                <span class="post-meta-item-text">阅读次数：</span>
              
                <span class="leancloud-visitors-count"></span>
            </span>
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">5.6k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">10 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="安装scrapy框架"><a href="#安装scrapy框架" class="headerlink" title="安装scrapy框架"></a>安装<code>scrapy</code>框架</h1><ol>
<li>安装<code>scrapy</code>：<code>pip install scrapy</code></li>
<li>windows下，还需要安装<code>pypiwin32</code>，防止报错。<code>pip install scrapy</code>。报<code>Visual C++ 14.0 is required</code>错误的话，安装<code>Visual C++ Build Tools</code>，<a href="https://blogs.msdn.microsoft.com/pythonengineering/2016/04/11/unable-to-find-vcvarsall-bat/" target="_blank" rel="noopener">Visual C++ Build Tools 2015下载地址</a></li>
</ol>
<h1 id="创建项目和爬虫"><a href="#创建项目和爬虫" class="headerlink" title="创建项目和爬虫"></a>创建项目和爬虫</h1><ol>
<li>创建项目：<code>scapy startproject [项目名称]</code></li>
<li>创建爬虫：命令行下，进入项目所在的路径，执行命令<code>scapy genspider [爬虫名字] [爬取的域名]</code>。注意：爬虫的名字不能和项目名字一样。</li>
</ol>
<h1 id="项目目录结构"><a href="#项目目录结构" class="headerlink" title="项目目录结构"></a>项目目录结构</h1><ol>
<li><code>items.py</code>：用来存放爬虫爬取下来数据的模型。</li>
<li><code>middlewares.py</code>：用来存放各种中间件的文件。</li>
<li><code>pipelines.py</code>：用来将items的模型存储到本地磁盘中。</li>
<li><code>settings.py</code>：本爬虫的一些配置信息（比如请求头、多久发送一次请求、ip代理池等）。</li>
<li><code>scrapy.cfg</code>：项目的配置文件。</li>
<li><code>spiders包</code>：以后所有的爬虫，都是存放到这个里面。</li>
</ol>
<h1 id="修改settings-py代码"><a href="#修改settings-py代码" class="headerlink" title="修改settings.py代码"></a>修改<code>settings.py</code>代码</h1><p>在做一个爬虫之前，一定要记得修改<code>setttings.py</code>中的设置。两个地方是强烈建议设置的。</p>
<ol>
<li><code>ROBOTSTXT_OBEY</code>设置为<code>False</code>。默认是<code>True</code>。即遵守机器协议，那么在爬虫的时候，<code>scrapy</code>首先去找<code>robots.txt</code>文件，如果没有找到。则直接停止爬取。</li>
<li><code>DEFAULT_REQUEST_HEADERS</code>添加<code>User-Agent</code>。这个也是告诉服务器，我这个请求是一个正常的请求，不是一个爬虫。</li>
<li>如果要激活<code>pipeline</code>，应该在<code>settings.py</code>中，设置<code>ITEM_PIPELINES</code>。</li>
<li>设置延时时间，<code>DOWNLOAD_DELAY = 1</code></li>
</ol>
<h1 id="运行scrapy项目"><a href="#运行scrapy项目" class="headerlink" title="运行scrapy项目"></a>运行scrapy项目</h1><p>运行<code>scrapy</code>项目。需要在终端，进入项目所在的路径，然后<code>scrapy crawl [爬虫名字]</code>即可运行指定的爬虫。如果不想每次都在命令行中运行，那么可以把这个命令写在一个文件中。以后就在<code>pycharm</code>中执行运行这个文件就可以了。比如现在新创建一个文件叫做<code>start.py</code>，然后在这个文件中填入以下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> cmdline</span><br><span class="line"></span><br><span class="line">cmdline.execute(<span class="string">"scrapy crawl qsbk"</span>.split())</span><br></pre></td></tr></table></figure>
<h1 id="糗事百科Scrapy爬虫笔记"><a href="#糗事百科Scrapy爬虫笔记" class="headerlink" title="糗事百科Scrapy爬虫笔记"></a>糗事百科Scrapy爬虫笔记</h1><ol>
<li><code>response</code>是一个<code>scrapy.http.response.html.HtmlResponse</code>对象。可以执行<code>xpath</code>和<code>css</code>语法提取数据。</li>
<li>提取出来的数据，是一个<code>Selector</code>或者是一个<code>SelectorList</code>对象。如果想要获取其中的字符串。使用<code>getall</code>或者<code>get</code>方法。</li>
<li><code>getall</code>方法：获取<code>Selector</code>中的所有文本。返回的是一个列表。</li>
<li><code>get</code>方法：获取的是<code>Selector</code>中的第一个文本。返回的是一个<code>str</code>类型。</li>
<li>如果数据解析回来，要传给<code>pipeline</code>处理。那么可以使用<code>yield</code>来返回。或者是收集所有的<code>item</code>。最后统一使用return返回。</li>
<li><code>item</code>：建议在<code>items.py</code>中定义好模型。以后就不要使用字典。</li>
<li><code>pipeline</code>：这个是专门用来保存数据的。其中有三个方法是会经常用的。<ul>
<li><code>open_spider(self,spider)</code>：当爬虫被打开的时候执行</li>
<li><code>process_item(self,item,spider</code>)：当爬虫有item传过来的时候会被调用</li>
<li><code>close_spider(self,spider)</code>：当爬虫关闭的时候会被调用</li>
</ul>
</li>
</ol>
<p>要激活<code>pipeline</code>，应该在<code>settings.py</code>中，设置<code>ITEM_PIPELINES</code>。示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">'qsbk.pipelines.QsbkPipeline'</span>: <span class="number">300</span>, <span class="comment">#数字小，优先级高</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="JsonItemExporter和JsonLinesItemExporter："><a href="#JsonItemExporter和JsonLinesItemExporter：" class="headerlink" title="JsonItemExporter和JsonLinesItemExporter："></a>JsonItemExporter和JsonLinesItemExporter：</h2><p>保存<code>json</code>数据的时候，可以使用这两个类，让操作变得更简单。</p>
<h3 id="JsonItemExport"><a href="#JsonItemExport" class="headerlink" title="JsonItemExport"></a>JsonItemExport</h3><p>每次把数据添加到内存中。最后统一写到磁盘中。</p>
<ul>
<li>优点：存储的数据是一个满足json规则的数据</li>
<li>缺点：如果数据量比较大，比较耗内存</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.exporters <span class="keyword">import</span> JsonItemExporter</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QsbkPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.fp = open(<span class="string">'duanzi.json'</span>, <span class="string">'wb'</span>)</span><br><span class="line">        self.exporter = JsonItemExporter(self.fp, ensure_ascii=<span class="keyword">False</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">        self.exporter.start_exporting()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line">        print(<span class="string">'爬虫开始'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        self.exporter.export_item(item)</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.exporter.finish_exporting()</span><br><span class="line">        self.fp.close()</span><br><span class="line">        print(<span class="string">'爬虫结束'</span>)</span><br></pre></td></tr></table></figure>
<h3 id="JsonLinesItemExporter"><a href="#JsonLinesItemExporter" class="headerlink" title="JsonLinesItemExporter"></a>JsonLinesItemExporter</h3><p>每次调用<code>export_item</code>的时候把这个<code>item</code>存在到磁盘中</p>
<ul>
<li>优点：每次处理数据的时候，直接存储到磁盘中，不耗内存。数据也比较安全。</li>
<li>缺点：每一个字典是一行，整个文件不是一个满足<code>json</code>格式的文件。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.exporters <span class="keyword">import</span> JsonLinesItemExporter</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QsbkPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.fp = open(<span class="string">'duanzi.json'</span>, <span class="string">'wb'</span>)</span><br><span class="line">        self.exporter = JsonLinesItemExporter(self.fp, ensure_ascii=<span class="keyword">False</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line">        print(<span class="string">'爬虫开始'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        self.exporter.export_item(item)</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.fp.close()</span><br><span class="line">        print(<span class="string">'爬虫结束'</span>)</span><br></pre></td></tr></table></figure>
<h1 id="CrawlSpider"><a href="#CrawlSpider" class="headerlink" title="CrawlSpider"></a>CrawlSpider</h1><p>可以实现，只要满足某个条件的<code>url</code>，都进行爬取。<code>CrawlSpider</code>继承自<code>Spider</code>，只不过是在之前的基础之上增加了新的功能，可以定义爬取的<code>url</code>的规则，以后<code>scrapy</code>碰到满足条件的<code>url</code>都进行爬取，而不用手动的<code>yield Request</code>。</p>
<h2 id="创建CrawlSpider爬虫"><a href="#创建CrawlSpider爬虫" class="headerlink" title="创建CrawlSpider爬虫"></a>创建<code>CrawlSpider</code>爬虫</h2><p>之前创建爬虫的方式是通过s<code>crapy genspider [爬虫名字] [域名]</code>的方式创建的。如果想要创建<code>CrawlSpider</code>爬虫，那么应该通过以下命令创建：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy genspider -c crawl [爬虫名字] [域名]</span><br></pre></td></tr></table></figure>
<h2 id="LinkExtractors链接提取器"><a href="#LinkExtractors链接提取器" class="headerlink" title="LinkExtractors链接提取器"></a>LinkExtractors链接提取器</h2><p>使用<code>LinkExtractors</code>可以不用程序员自己提取想要的<code>url</code>，然后发送请求。这些工作都可以交给<code>LinkExtractors</code>，他会在所有爬的页面中找到满足规则的<code>url</code>，实现自动的爬取。以下对<code>LinkExtractors</code>类做一个简单的介绍：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">scrapy</span>.<span class="title">linkextractors</span>.<span class="title">LinkExtractor</span><span class="params">(</span></span></span><br><span class="line"><span class="class"><span class="params">    allow = <span class="params">()</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    deny = <span class="params">()</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    allow_domains = <span class="params">()</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    deny_domains = <span class="params">()</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    deny_extensions = None,</span></span></span><br><span class="line"><span class="class"><span class="params">    restrict_xpaths = <span class="params">()</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    tags = <span class="params">(<span class="string">'a'</span>,<span class="string">'area'</span>)</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    attrs = <span class="params">(<span class="string">'href'</span>)</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    canonicalize = True,</span></span></span><br><span class="line"><span class="class"><span class="params">    unique = True,</span></span></span><br><span class="line"><span class="class"><span class="params">    process_value = None</span></span></span><br><span class="line"><span class="class"><span class="params">)</span></span></span><br></pre></td></tr></table></figure>
<p>主要参数讲解：</p>
<ul>
<li><code>allow</code>：允许的url。所有满足这个正则表达式的url都会被提取。</li>
<li><code>deny</code>：禁止的url。所有满足这个正则表达式的url都不会被提取。</li>
<li><code>allow_domains</code>：允许的域名。只有在这个里面指定的域名的url才会被提取。</li>
<li><code>deny_domains</code>：禁止的域名。所有在这个里面指定的域名的url都不会被提取。</li>
<li><code>restrict_xpaths</code>：严格的xpath。和allow共同过滤链接。</li>
</ul>
<h2 id="Rule规则类"><a href="#Rule规则类" class="headerlink" title="Rule规则类"></a>Rule规则类</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">scrapy</span>.<span class="title">spiders</span>.<span class="title">Rule</span><span class="params">(</span></span></span><br><span class="line"><span class="class"><span class="params">    link_extractor, </span></span></span><br><span class="line"><span class="class"><span class="params">    callback = None, </span></span></span><br><span class="line"><span class="class"><span class="params">    cb_kwargs = None, </span></span></span><br><span class="line"><span class="class"><span class="params">    follow = None, </span></span></span><br><span class="line"><span class="class"><span class="params">    process_links = None, </span></span></span><br><span class="line"><span class="class"><span class="params">    process_request = None</span></span></span><br><span class="line"><span class="class"><span class="params">)</span></span></span><br></pre></td></tr></table></figure>
<p>主要参数讲解：</p>
<ul>
<li><code>link_extractor</code>：一个<code>LinkExtractor</code>对象，用于定义爬取规则。</li>
<li><code>callback</code>：满足这个规则的url，应该要执行哪个回调函数。因为<code>CrawlSpider</code>使用了<code>parse</code>作为回调函数，因此不要覆盖<code>parse</code>作为回调函数自己的回调函数。</li>
<li><code>follow</code>：指定根据该规则从response中提取的链接是否需要跟进。</li>
<li><code>process_links</code>：从<code>link_extractor</code>中获取到链接后会传递给这个函数，用来过滤不需要爬取的链接。</li>
</ul>
<h2 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h2><p><code>LinkExtractor</code>和<code>Rule</code>决定爬虫的具体走向。</p>
<ol>
<li><code>allow</code>设置规则的方法：能够限制在我们想要的url上，不与其它的url相同的正则表达式即可。</li>
<li><code>follow</code>使用场景：如果在爬取页面的时候，需要将满足当前条件的url再进行跟进，那么就设置为<code>True</code>。否则设置为<code>False</code>。</li>
<li><code>callback</code>使用场景：如果这个url对应的页面，只是为了获取更多的url，并不需要里面的数据，可以不指定callback。如果想获取url对应页面中的数据，那么久需要制定一个callback。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"><span class="keyword">from</span> scrapy.spiders <span class="keyword">import</span> CrawlSpider, Rule</span><br><span class="line"><span class="keyword">from</span> wxapp.items <span class="keyword">import</span> WxappItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WxappSpiderSpider</span><span class="params">(CrawlSpider)</span>:</span></span><br><span class="line">    name = <span class="string">'wxapp_spider'</span></span><br><span class="line">    allowed_domains = [<span class="string">'wxapp-union.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://www.wxapp-union.com/portal.php?mod=list&amp;catid=2&amp;page=1'</span>]</span><br><span class="line"></span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(allow=<span class="string">r'.+mod=list&amp;catid=2&amp;page=/d'</span>), follow=<span class="keyword">True</span>),</span><br><span class="line">        Rule(LinkExtractor(allow=<span class="string">r'.+article-.+\.html'</span>), callback=<span class="string">'parse_detail'</span>, follow=<span class="keyword">False</span>),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_detail</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        title = response.xpath(<span class="string">"//h1[@class='ph']/text()"</span>).get()</span><br><span class="line">        author_p = response.xpath(<span class="string">"//p[@class='authors']"</span>)</span><br><span class="line">        author = author_p.xpath(<span class="string">"./a/text()"</span>).get()</span><br><span class="line">        pub_time = author_p.xpath(<span class="string">"./span/text()"</span>).get()</span><br><span class="line">        article_content = response.xpath(<span class="string">"//td[@id='article_content']//text()"</span>).getall()</span><br><span class="line">        content = <span class="string">''</span>.join(article_content).strip()</span><br><span class="line">        item = WxappItem(author=author, title=title, pub_time=pub_time,content=content)</span><br><span class="line">        <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure>
      
    </div>

    

    
    
    

    

    
      
    
    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>赞赏作者</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatreward.png" alt="WP 微信支付">
        <p>微信支付</p>
      </div>
    

    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/scrapy/" rel="tag"># scrapy</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/02/09/《MySQL必知必会》笔记/" rel="next" title="《MySQL必知必会》笔记">
                <i class="fa fa-chevron-left"></i> 《MySQL必知必会》笔记
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/02/17/爬虫笔记01/" rel="prev" title="爬虫笔记01 - 数据解析">
                爬虫笔记01 - 数据解析 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/memory.jpg" alt="WP">
            
              <p class="site-author-name" itemprop="name">WP</p>
              <p class="site-description motion-element" itemprop="description">飞机从头顶飞过<br>流星也划破那夜空</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">13</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">6</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">8</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#安装scrapy框架"><span class="nav-number">1.</span> <span class="nav-text">安装scrapy框架</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#创建项目和爬虫"><span class="nav-number">2.</span> <span class="nav-text">创建项目和爬虫</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#项目目录结构"><span class="nav-number">3.</span> <span class="nav-text">项目目录结构</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#修改settings-py代码"><span class="nav-number">4.</span> <span class="nav-text">修改settings.py代码</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#运行scrapy项目"><span class="nav-number">5.</span> <span class="nav-text">运行scrapy项目</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#糗事百科Scrapy爬虫笔记"><span class="nav-number">6.</span> <span class="nav-text">糗事百科Scrapy爬虫笔记</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#JsonItemExporter和JsonLinesItemExporter："><span class="nav-number">6.1.</span> <span class="nav-text">JsonItemExporter和JsonLinesItemExporter：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#JsonItemExport"><span class="nav-number">6.1.1.</span> <span class="nav-text">JsonItemExport</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#JsonLinesItemExporter"><span class="nav-number">6.1.2.</span> <span class="nav-text">JsonLinesItemExporter</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CrawlSpider"><span class="nav-number">7.</span> <span class="nav-text">CrawlSpider</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#创建CrawlSpider爬虫"><span class="nav-number">7.1.</span> <span class="nav-text">创建CrawlSpider爬虫</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#LinkExtractors链接提取器"><span class="nav-number">7.2.</span> <span class="nav-text">LinkExtractors链接提取器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Rule规则类"><span class="nav-number">7.3.</span> <span class="nav-text">Rule规则类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#使用说明"><span class="nav-number">7.4.</span> <span class="nav-text">使用说明</span></a></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">WP</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">站点总字数：</span>
    
    <span title="站点总字数">98k</span>
  

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    
    <span title="站点阅读时长">2:58</span>
  
</div>









        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>














  
    
    
  
  <script color="0,0,255" opacity="0.5" zindex="-1" count="99" src="/lib/canvas-nest/canvas-nest.min.js"></script>



  
  











  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script src="/lib/three/three.min.js"></script>

  
  <script src="/lib/three/three-waves.min.js"></script>


  


  <script src="/js/src/utils.js?v=6.7.0"></script>

  <script src="/js/src/motion.js?v=6.7.0"></script>



  
  


  <script src="/js/src/affix.js?v=6.7.0"></script>

  <script src="/js/src/schemes/pisces.js?v=6.7.0"></script>



  
  <script src="/js/src/scrollspy.js?v=6.7.0"></script>
<script src="/js/src/post-details.js?v=6.7.0"></script>



  


  <script src="/js/src/bootstrap.js?v=6.7.0"></script>



  
  




  

<script src="//cdn1.lncld.net/static/js/3.11.1/av-min.js"></script>



<script src="//unpkg.com/valine/dist/Valine.min.js"></script>

<script>
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail';
  guest = guest.split(',').filter(function (item) {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: 'IrCihvbStzYVX1cVfwYfUjpt-gzGzoHsz',
    appKey: 'U1FLNq52nK27I2BQq9TCSAdt',
    placeholder: '来玩啊',
    avatar: 'mp',
    meta: guest,
    pageSize: '10' || 10,
    visitor: true
  });
</script>



  





  

  

  

  

  

  

  

  

  

  

  

  

  

  
</body>
</html>
